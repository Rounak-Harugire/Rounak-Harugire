{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP5MIcaDNPdcJuwJzIDCTDK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":346},"id":"8fHC7Ey1EdI5","executionInfo":{"status":"error","timestamp":1736577286121,"user_tz":-330,"elapsed":5599,"user":{"displayName":"ROUNAK HARUGIRE","userId":"18285850768920051310"}},"outputId":"515ec6d9-9c8d-4dc7-8fa0-6e80084a4aed"},"outputs":[{"output_type":"error","ename":"error","evalue":"OpenCV(4.10.0) /io/opencv/modules/imgproc/src/resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-aa98058946b2>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# In a real scenario, this should be a larger dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m image_features = {\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;34m'image1.jpg'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'a dog running in a park'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'image1.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;34m'image2.jpg'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'a cat sitting on a sofa'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'image2.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;34m'image3.jpg'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'a car driving on a road'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'image3.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-1-aa98058946b2>\u001b[0m in \u001b[0;36mpreprocess_image\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Resize to fixed size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Convert to grayscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0morb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mORB_create\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Feature detector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31merror\u001b[0m: OpenCV(4.10.0) /io/opencv/modules/imgproc/src/resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n"]}],"source":["import cv2\n","import numpy as np\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.neighbors import NearestNeighbors\n","\n","# Load and preprocess the image\n","def preprocess_image(image_path):\n","    image = cv2.imread(image_path)\n","    image = cv2.resize(image, (224, 224))  # Resize to fixed size\n","    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n","    orb = cv2.ORB_create()  # Feature detector\n","    keypoints, descriptors = orb.detectAndCompute(gray, None)\n","    return descriptors\n","\n","# Sample dataset of image features and corresponding captions\n","# In a real scenario, this should be a larger dataset\n","image_features = {\n","    'image1.jpg': ('a dog running in a park', preprocess_image('image1.jpg')),\n","    'image2.jpg': ('a cat sitting on a sofa', preprocess_image('image2.jpg')),\n","    'image3.jpg': ('a car driving on a road', preprocess_image('image3.jpg'))\n","}\n","\n","# Extract features and captions\n","features = []\n","captions = []\n","for caption, feature in image_features.values():\n","    features.append(np.mean(feature, axis=0))  # Average descriptors for simplicity\n","    captions.append(caption)\n","\n","# Fit a nearest neighbors model\n","vectorizer = CountVectorizer()\n","X_captions = vectorizer.fit_transform(captions)\n","nn = NearestNeighbors(n_neighbors=1)\n","nn.fit(X_captions.toarray())\n","\n","# Function to generate a caption for a new image\n","def generate_caption(image_path):\n","    image_feature = preprocess_image(image_path)\n","    image_feature_mean = np.mean(image_feature, axis=0).reshape(1, -1)\n","    _, indices = nn.kneighbors(image_feature_mean)\n","    return captions[indices[0][0]]\n","\n","# Example usage\n","new_image_path = 'new_image.jpg'\n","caption = generate_caption(new_image_path)\n","print(\"Generated Caption:\", caption)\n"]}]}