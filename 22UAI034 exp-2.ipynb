{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPFKyN+lTsJaxxv1G7C+GAp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aZQ0DwgC2tdr","executionInfo":{"status":"ok","timestamp":1736724664680,"user_tz":-330,"elapsed":7886,"user":{"displayName":"ROUNAK HARUGIRE","userId":"18285850768920051310"}},"outputId":"bdae5d89-74b9-4b82-89ff-693ccdbeb99e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.8)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.11.6)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.67.1)\n"]}],"source":["pip install nltk"]},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt_tab')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m1EyQlPG3pzx","executionInfo":{"status":"ok","timestamp":1736724888165,"user_tz":-330,"elapsed":391,"user":{"displayName":"ROUNAK HARUGIRE","userId":"18285850768920051310"}},"outputId":"d05cba51-55a5-4efa-d231-03df39b387d1"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["import nltk\n","from nltk.tokenize import word_tokenize, sent_tokenize\n","text = \"hello rahul how are you\"\n","words = word_tokenize(text)\n","print(\"\\nWord Tokenization:\")\n","for i, word in enumerate(words, 1):\n","    print(f\"{i}: {word}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D5EguXI44N6J","executionInfo":{"status":"ok","timestamp":1736726940997,"user_tz":-330,"elapsed":402,"user":{"displayName":"ROUNAK HARUGIRE","userId":"18285850768920051310"}},"outputId":"33772149-9a9d-4a11-837b-5358870b6b53"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Word Tokenization:\n","1: hello\n","2: rahul\n","3: how\n","4: are\n","5: you\n"]}]},{"cell_type":"code","source":["import nltk\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","\n","text = \"hello rounak how are you\"\n","words = word_tokenize(text)\n","stop_words = set(stopwords.words('english'))\n","filtered_words = [word for word in words if word.lower() not in stop_words]\n","\n","print(\"Filtered Words:\", filtered_words)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pvX9Bxft5ZtS","executionInfo":{"status":"ok","timestamp":1736725455390,"user_tz":-330,"elapsed":632,"user":{"displayName":"ROUNAK HARUGIRE","userId":"18285850768920051310"}},"outputId":"64e90437-d13a-4da3-e61d-7880a2ad05e9"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Filtered Words: ['hello', 'rounak']\n"]}]}]}